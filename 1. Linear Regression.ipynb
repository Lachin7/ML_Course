{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16adc323",
   "metadata": {},
   "source": [
    "<br><font face=\"Times New Roman\" size=5><div dir=ltr align=center>\n",
    "<font color=blue size=8>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=red size=5>\n",
    "    Sharif University of Technology - Computer Engineering Department <br>\n",
    "    Fall 2022<br> <br>\n",
    "<font color=black size=6>\n",
    "    Homework 2: Practical - Linear Regression\n",
    "    </div>\n",
    "<br><br>\n",
    "<font size=4>\n",
    "   **Name**: Lachin Naghashyar<br>\n",
    "   **Student ID**: 98110179<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585264a",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=4><div dir=ltr>\n",
    "# Problem 1: Linear Regression Model (40 + 30 optional points)\n",
    "According to <a href=\"https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Classical_Models/Linear%20regression.ipynb\"><font face=\"Roboto\">Linear Regression Notebook</font></a>, train a linear regression model on an arbitrary dataset. Explain your chosen dataset and split your data into train and test sets, then predict values for the test set using your trained model. Try to find the best hyperparameters for your model. (Using Lasso Regression, Ridge Regression or Elastic Net and comparing them will have extra optional points)\n",
    "<br> Explain each step of your workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing Data\n",
    "I used the Real estate price prediction data set which was built for regression analysis and includes the date of purchase, house age, location, distance to nearest MRT station, and house price of unit area. We can take a look at our data below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 414 entries, 0 to 413\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   No                                      414 non-null    int64  \n",
      " 1   X1 transaction date                     414 non-null    float64\n",
      " 2   X2 house age                            414 non-null    float64\n",
      " 3   X3 distance to the nearest MRT station  414 non-null    float64\n",
      " 4   X4 number of convenience stores         414 non-null    int64  \n",
      " 5   X5 latitude                             414 non-null    float64\n",
      " 6   X6 longitude                            414 non-null    float64\n",
      " 7   Y house price of unit area              414 non-null    float64\n",
      "dtypes: float64(6), int64(2)\n",
      "memory usage: 26.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "           No  X1 transaction date  X2 house age  \\\ncount  414.00               414.00        414.00   \nmean   207.50              2013.15         17.71   \nstd    119.66                 0.28         11.39   \nmin      1.00              2012.67          0.00   \n25%    104.25              2012.92          9.02   \n50%    207.50              2013.17         16.10   \n75%    310.75              2013.42         28.15   \nmax    414.00              2013.58         43.80   \n\n       X3 distance to the nearest MRT station  \\\ncount                                  414.00   \nmean                                  1083.89   \nstd                                   1262.11   \nmin                                     23.38   \n25%                                    289.32   \n50%                                    492.23   \n75%                                   1454.28   \nmax                                   6488.02   \n\n       X4 number of convenience stores  X5 latitude  X6 longitude  \\\ncount                           414.00       414.00        414.00   \nmean                              4.09        24.97        121.53   \nstd                               2.95         0.01          0.02   \nmin                               0.00        24.93        121.47   \n25%                               1.00        24.96        121.53   \n50%                               4.00        24.97        121.54   \n75%                               6.00        24.98        121.54   \nmax                              10.00        25.01        121.57   \n\n       Y house price of unit area  \ncount                      414.00  \nmean                        37.98  \nstd                         13.61  \nmin                          7.60  \n25%                         27.70  \n50%                         38.45  \n75%                         46.60  \nmax                        117.50  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>X1 transaction date</th>\n      <th>X2 house age</th>\n      <th>X3 distance to the nearest MRT station</th>\n      <th>X4 number of convenience stores</th>\n      <th>X5 latitude</th>\n      <th>X6 longitude</th>\n      <th>Y house price of unit area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>414.00</td>\n      <td>414.00</td>\n      <td>414.00</td>\n      <td>414.00</td>\n      <td>414.00</td>\n      <td>414.00</td>\n      <td>414.00</td>\n      <td>414.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>207.50</td>\n      <td>2013.15</td>\n      <td>17.71</td>\n      <td>1083.89</td>\n      <td>4.09</td>\n      <td>24.97</td>\n      <td>121.53</td>\n      <td>37.98</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>119.66</td>\n      <td>0.28</td>\n      <td>11.39</td>\n      <td>1262.11</td>\n      <td>2.95</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>13.61</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00</td>\n      <td>2012.67</td>\n      <td>0.00</td>\n      <td>23.38</td>\n      <td>0.00</td>\n      <td>24.93</td>\n      <td>121.47</td>\n      <td>7.60</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>104.25</td>\n      <td>2012.92</td>\n      <td>9.02</td>\n      <td>289.32</td>\n      <td>1.00</td>\n      <td>24.96</td>\n      <td>121.53</td>\n      <td>27.70</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>207.50</td>\n      <td>2013.17</td>\n      <td>16.10</td>\n      <td>492.23</td>\n      <td>4.00</td>\n      <td>24.97</td>\n      <td>121.54</td>\n      <td>38.45</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>310.75</td>\n      <td>2013.42</td>\n      <td>28.15</td>\n      <td>1454.28</td>\n      <td>6.00</td>\n      <td>24.98</td>\n      <td>121.54</td>\n      <td>46.60</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>414.00</td>\n      <td>2013.58</td>\n      <td>43.80</td>\n      <td>6488.02</td>\n      <td>10.00</td>\n      <td>25.01</td>\n      <td>121.57</td>\n      <td>117.50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Real estate.csv')\n",
    "df\n",
    "df.info()\n",
    "display(df.describe().round(2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, it consists of different features for $X$ and also has the price of unit area as its final output ($Y$). In Regression, we are searching for relationships among variables. For example here, we are looking for a function that maps $X_i$ features to the price.\n",
    "Hopefully, we don't have any null value or any strings or objects, so we don't need data cleaning.\n",
    "We can separate the data into $X$ and $Y$ arrays:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:7].to_numpy()\n",
    "Y = df.iloc[:, 7:].to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data into Train and Test sets:\n",
    "we use about 80 percent in the training and the rest in test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "training_examples = int(X.shape[0] * 0.8)\n",
    "X_train = X[:training_examples,:]\n",
    "Y_train = Y[:training_examples,:]\n",
    "X_test = X[training_examples:,:]\n",
    "Y_test = Y[training_examples:,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Model (using scikit-learn package)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import some packages needed:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we do the training using the fit function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "59.40924577639657"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "mean_squared_error(Y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune the hyper parameters\n",
    "\n",
    "For the LinearRegression function in sklearn we can make use of the documentations:\n",
    "class sklearn.linear_model.LinearRegression(*, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False)\n",
    "For example we can try normalizing the data (which can be done by setting the fit_intercept parameter to False):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "59.993134416189"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=False).fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "mean_squared_error(Y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, the error didn't change much by normalizing the data, and it even increased slightly.\n",
    "It seems that LinearRegression model does not have that many parameters that can be tuned, however, We can use sklearn.linear_model.SGDRegressor, which will provide many possibilities for tuning hyperparameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SGDRegressor\n",
    "class sklearn.linear_model.SGDRegressor(loss='squared_error', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01, power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False)\n",
    "\n",
    "Linear model fitted by minimizing a regularized empirical loss with SGD.\n",
    "\n",
    "SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).\n",
    "\n",
    "The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "59.6629795635549"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "reg = make_pipeline(StandardScaler(), SGDRegressor())\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In SGDRegressor we have the penalty{‘l2’, ‘l1’, ‘elasticnet’}, default=’l2’ field. Choosing l1, l2 and elasticnet will result in a Lasso, Ridge and elasticnet cost models respectively."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "59.60589578716992"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "59.705241257862006"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='l1'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that they perform similar to each other and elasticnet might be slightly better in this example. We know that Lasso will eliminate many features, and reduce overfitting in your linear model. Ridge will reduce the impact of features that are not important in predicting your y values. Elastic Net combines feature elimination from Lasso and feature coefficient reduction from the Ridge model to improve your model's predictions (medium.com). We can also tune other parameters such as learning rate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "60.15492728876293"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='constant'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "1.1730253299359679e+24"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='optimal'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "59.41602680373095"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='adaptive'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that adaptive learning rate performs slightly better."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "59.46618545262922"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='adaptive', max_iter=3000))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "59.42554674310714"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='adaptive', alpha=0.0000001))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Moreover, it seems like altering the max_iteration and alpha numbers doesn't affect the result that much."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
