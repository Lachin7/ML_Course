{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16adc323",
   "metadata": {},
   "source": [
    "<br><font face=\"Times New Roman\" size=5><div dir=ltr align=center>\n",
    "<font color=blue size=8>\n",
    "    Introduction to Machine Learning <br>\n",
    "<font color=red size=5>\n",
    "    Sharif University of Technology - Computer Engineering Department <br>\n",
    "    Fall 2022<br> <br>\n",
    "<font color=black size=6>\n",
    "    Homework 2: Practical - Linear Regression\n",
    "    </div>\n",
    "<br><br>\n",
    "<font size=4>\n",
    "   **Name**: Lachin Naghashyar<br>\n",
    "   **Student ID**: 98110179<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585264a",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=4><div dir=ltr>\n",
    "# Problem 1: Linear Regression Model (40 + 30 optional points)\n",
    "According to <a href=\"https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Classical_Models/Linear%20regression.ipynb\"><font face=\"Roboto\">Linear Regression Notebook</font></a>, train a linear regression model on an arbitrary dataset. Explain your chosen dataset and split your data into train and test sets, then predict values for the test set using your trained model. Try to find the best hyperparameters for your model. (Using Lasso Regression, Ridge Regression or Elastic Net and comparing them will have extra optional points)\n",
    "<br> Explain each step of your workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing Data\n",
    "I used the Real estate price prediction data set which was built for regression analysis and includes the date of purchase, house age, location, distance to nearest MRT station, and house price of unit area. We can take a look at our data below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      No  X1 transaction date  X2 house age  \\\n0      1             2012.917          32.0   \n1      2             2012.917          19.5   \n2      3             2013.583          13.3   \n3      4             2013.500          13.3   \n4      5             2012.833           5.0   \n..   ...                  ...           ...   \n409  410             2013.000          13.7   \n410  411             2012.667           5.6   \n411  412             2013.250          18.8   \n412  413             2013.000           8.1   \n413  414             2013.500           6.5   \n\n     X3 distance to the nearest MRT station  X4 number of convenience stores  \\\n0                                  84.87882                               10   \n1                                 306.59470                                9   \n2                                 561.98450                                5   \n3                                 561.98450                                5   \n4                                 390.56840                                5   \n..                                      ...                              ...   \n409                              4082.01500                                0   \n410                                90.45606                                9   \n411                               390.96960                                7   \n412                               104.81010                                5   \n413                                90.45606                                9   \n\n     X5 latitude  X6 longitude  Y house price of unit area  \n0       24.98298     121.54024                        37.9  \n1       24.98034     121.53951                        42.2  \n2       24.98746     121.54391                        47.3  \n3       24.98746     121.54391                        54.8  \n4       24.97937     121.54245                        43.1  \n..           ...           ...                         ...  \n409     24.94155     121.50381                        15.4  \n410     24.97433     121.54310                        50.0  \n411     24.97923     121.53986                        40.6  \n412     24.96674     121.54067                        52.5  \n413     24.97433     121.54310                        63.9  \n\n[414 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>X1 transaction date</th>\n      <th>X2 house age</th>\n      <th>X3 distance to the nearest MRT station</th>\n      <th>X4 number of convenience stores</th>\n      <th>X5 latitude</th>\n      <th>X6 longitude</th>\n      <th>Y house price of unit area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2012.917</td>\n      <td>32.0</td>\n      <td>84.87882</td>\n      <td>10</td>\n      <td>24.98298</td>\n      <td>121.54024</td>\n      <td>37.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2012.917</td>\n      <td>19.5</td>\n      <td>306.59470</td>\n      <td>9</td>\n      <td>24.98034</td>\n      <td>121.53951</td>\n      <td>42.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2013.583</td>\n      <td>13.3</td>\n      <td>561.98450</td>\n      <td>5</td>\n      <td>24.98746</td>\n      <td>121.54391</td>\n      <td>47.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2013.500</td>\n      <td>13.3</td>\n      <td>561.98450</td>\n      <td>5</td>\n      <td>24.98746</td>\n      <td>121.54391</td>\n      <td>54.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2012.833</td>\n      <td>5.0</td>\n      <td>390.56840</td>\n      <td>5</td>\n      <td>24.97937</td>\n      <td>121.54245</td>\n      <td>43.1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>409</th>\n      <td>410</td>\n      <td>2013.000</td>\n      <td>13.7</td>\n      <td>4082.01500</td>\n      <td>0</td>\n      <td>24.94155</td>\n      <td>121.50381</td>\n      <td>15.4</td>\n    </tr>\n    <tr>\n      <th>410</th>\n      <td>411</td>\n      <td>2012.667</td>\n      <td>5.6</td>\n      <td>90.45606</td>\n      <td>9</td>\n      <td>24.97433</td>\n      <td>121.54310</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>411</th>\n      <td>412</td>\n      <td>2013.250</td>\n      <td>18.8</td>\n      <td>390.96960</td>\n      <td>7</td>\n      <td>24.97923</td>\n      <td>121.53986</td>\n      <td>40.6</td>\n    </tr>\n    <tr>\n      <th>412</th>\n      <td>413</td>\n      <td>2013.000</td>\n      <td>8.1</td>\n      <td>104.81010</td>\n      <td>5</td>\n      <td>24.96674</td>\n      <td>121.54067</td>\n      <td>52.5</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>414</td>\n      <td>2013.500</td>\n      <td>6.5</td>\n      <td>90.45606</td>\n      <td>9</td>\n      <td>24.97433</td>\n      <td>121.54310</td>\n      <td>63.9</td>\n    </tr>\n  </tbody>\n</table>\n<p>414 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Real estate.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, it consists of different features for $X$ and also has the price of unit area as its final output ($Y$). In Regression, we are searching for relationships among variables. For example here, we are looking for a function that maps $X_i$ features to the price.\n",
    "We can separate the data into $X$ and $Y$ arrays:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:7].to_numpy()\n",
    "Y = df.iloc[:, 7:].to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data into Train and Test sets:\n",
    "we use about 80 percent in the training and the rest in test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "training_examples = int(X.shape[0] * 0.8)\n",
    "X_train = X[:training_examples,:]\n",
    "Y_train = Y[:training_examples,:]\n",
    "X_test = X[training_examples:,:]\n",
    "Y_test = Y[training_examples:,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Model (using scikit-learn package)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import some packages needed:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we do the training using the fit function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "59.40924577639657"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "mean_squared_error(Y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tune the hyper parameters\n",
    "\n",
    "For the LinearRegression function in sklearn we can make use of the documentations:\n",
    "class sklearn.linear_model.LinearRegression(*, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False)\n",
    "For example we can try normalizing the data (which can be done by setting the fit_intercept parameter to False):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "59.993134416189"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=False).fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "mean_squared_error(Y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, the error didn't change much by normalizing the data, and it even increased slightly.\n",
    "It seems that LinearRegression model does not have that many parameters that can be tuned, however, We can use sklearn.linear_model.SGDRegressor, which will provide many possibilities for tuning hyperparameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SGDRegressor\n",
    "class sklearn.linear_model.SGDRegressor(loss='squared_error', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01, power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False)\n",
    "\n",
    "Linear model fitted by minimizing a regularized empirical loss with SGD.\n",
    "\n",
    "SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).\n",
    "\n",
    "The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "59.6629795635549"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Always scale the input. The most convenient way is to use a pipeline.\n",
    "reg = make_pipeline(StandardScaler(), SGDRegressor())\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In SGDRegressor we have the penalty{â€˜l2â€™, â€˜l1â€™, â€˜elasticnetâ€™}, default=â€™l2â€™ field. Choosing l1, l2 and elasticnet will result in a Lasso, Ridge and elasticnet cost models respectively."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "59.60589578716992"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "59.705241257862006"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='l1'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that they perform similar to each other and elasticnet might be slightly better in this example. We know that Lasso will eliminate many features, and reduce overfitting in your linear model. Ridge will reduce the impact of features that are not important in predicting your y values. Elastic Net combines feature elimination from Lasso and feature coefficient reduction from the Ridge model to improve your model's predictions (medium.com). We can also tune other parameters such as learning rate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "60.15492728876293"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='constant'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "1.1730253299359679e+24"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='optimal'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "59.41602680373095"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='adaptive'))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that adaptive learning rate performs slightly better."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "59.46618545262922"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='adaptive', max_iter=3000))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "59.42554674310714"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(penalty='elasticnet',learning_rate='adaptive', alpha=0.0000001))\n",
    "reg.fit(X_train, Y_train.ravel())\n",
    "mean_squared_error(Y_test.ravel(), reg.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Moreover, it seems like altering the max_iteration and alpha numbers doesn't affect the result that much."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
